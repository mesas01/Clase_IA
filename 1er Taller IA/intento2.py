import numpy as np  # Para operaciones num칠ricas y manejo de arrays
import pandas as pd  # Para la manipulaci칩n y an치lisis de datos
from sklearn.model_selection import train_test_split  # Para dividir los datos en conjuntos de entrenamiento y prueba
from sklearn.preprocessing import StandardScaler  # Para la normalizaci칩n de los datos
import matplotlib.pyplot as plt  # Para la visualizaci칩n de datos
from ipywidgets import interact, FloatSlider  # Para crear interfaces interactivas en Jupyter notebooks


# Cargar los datos desde un archivo Excel
datosExcel = pd.read_excel('Real estate valuation data set.xlsx')

# Seleccionar las caracter칤sticas y la variables de las casas
caracteristicas = ['X2 house age', 'X3 distance to the nearest MRT station', 'X4 number of convenience stores', 'X5 latitude', 'X6 longitude']
X = datosExcel[caracteristicas].values
Y = datosExcel['Y house price of unit area'].values.reshape(-1, 1)

# funcion que Divide los datos en conjuntos de entrenamiento y prueba, y normaliza las caracter칤sticas.
def dividir_y_normalizar_datos(X, Y):

    X_entrenamiento, X_prueba, Y_entrenamiento, Y_prueba = train_test_split(X, Y, test_size=0.2, random_state=42)
    escalador_X = StandardScaler()
    X_entrenamiento_escalado = escalador_X.fit_transform(X_entrenamiento)
    X_prueba_escalado = escalador_X.transform(X_prueba)
    X_entrenamiento_escalado = np.hstack([np.ones((X_entrenamiento_escalado.shape[0], 1)), X_entrenamiento_escalado])
    X_prueba_escalado = np.hstack([np.ones((X_prueba_escalado.shape[0], 1)), X_prueba_escalado])
    return X_entrenamiento_escalado, X_prueba_escalado, Y_entrenamiento, Y_prueba


def calcular_hipotesis(X, theta):
    """
    Calcula la hip칩tesis h_洧랚(X) para un conjunto de datos X y par치metros 洧랚.
    """
    return np.dot(X, theta)


def calcular_costo(X, Y, theta):
    """
    Calcula el valor de la funci칩n de costo J(洧랚).
    """
    m = len(Y)
    h = calcular_hipotesis(X, theta)
    return (1/(2*m)) * np.sum(np.square(h - Y))

def calcular_gradiente(X, Y, theta):
    """
    Calcula el gradiente de la funci칩n de costo.
    """
    m = len(Y)
    h = calcular_hipotesis(X, theta)
    return (1/m) * np.dot(X.T, (h - Y))

def actualizar_parametros(theta, tasa_aprendizaje, gradiente):
    """
    Actualiza los par치metros 洧랚 utilizando el gradiente de la funci칩n de costo.
    """
    return theta - tasa_aprendizaje * gradiente


def main():
    X_entrenamiento_escalado, X_prueba_escalado, Y_entrenamiento, Y_prueba = dividir_y_normalizar_datos(X, Y)

    theta_inicial = np.zeros((X_entrenamiento_escalado.shape[1], 1))

    tasa_aprendizaje = 0.01
    iteraciones = 1000

    theta = theta_inicial
    for i in range(iteraciones):
        gradiente = calcular_gradiente(X_entrenamiento_escalado, Y_entrenamiento, theta)
        theta = actualizar_parametros(theta, tasa_aprendizaje, gradiente)

    # Ejemplo de c칩mo se podr칤an imprimir los resultados del entrenamiento
    costo_final = calcular_costo(X_entrenamiento_escalado, Y_entrenamiento, theta)
    print("Costo final despu칠s del entrenamiento:", costo_final)
    print("Par치metros theta finales:", theta)


if __name__ == "__main__":
    main()
